{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Lab2-Computer-Vision.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Jgc_q-x8edKD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnyTxjK_GbOD"
      },
      "source": [
        "# Exemplo de Visão Computacional\n",
        "Analisar um cenário onde podemos reconhecer diferentes peças de roupa, com base em um conjunto de dados contendo 10 tipos diferentes."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " ## TensorFlow\n",
        "Para cada neuronio \"por baixo dos panos\" ele cria 128 núcleos (células de processamento). Para cada um desses 128 neurônios, ele cria automaticamente uma lista de pesos ($W$) e um bias ($b$). Ele já deixa a fórmula $z = (W \\cdot X) + b$ pronta dentro de cada um deles. Ele já aplica a função de ativação ReLU no resultado.\n",
        "TensorFlow biblioteca de alto nível."
      ],
      "metadata": {
        "id": "BGYTy699r7vy"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3KzJyjv3rnA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ca82f15-74fc-4c48-8952-965c9d7558b8"
      },
      "source": [
        "# importação do TensorFlow\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.19.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sKswgmaMenc"
      },
      "source": [
        "Treinar uma rede neural para reconhecer peças de roupa a partir de um conjunto de dados comum chamado Fashion MNIST.(https://github.com/zalandoresearch/fashion-mnist).\n",
        "\n",
        "Ele contém 70.000 peças de roupa em 10 categorias diferentes. Cada peça de roupa está em uma imagem em tons de cinza de 28x28 pixels. Você pode ver alguns exemplos aqui:\n",
        "\n",
        "![alt text](https://github.com/zalandoresearch/fashion-mnist/raw/master/doc/img/fashion-mnist-sprite.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_n1U5do3u_F"
      },
      "source": [
        "Os dados do Fashion MNIST estão disponíveis diretamente na API de conjuntos de dados do tf.keras. Você os carrega assim:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmxkHFpt31bM"
      },
      "source": [
        "mnist = tf.keras.datasets.fashion_mnist"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTdRgExe4TRB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ff8c266-a6cd-4f4a-a21b-1ac9cafd337c"
      },
      "source": [
        "#Chamar o método load_data nesse objeto retornará dois conjuntos de duas listas, que serão os valores de treinamento e teste para os gráficos que contêm as peças de roupa e seus respectivos rótulos\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Papel do Programador(training_images[5]):\n",
        "Faz uma inspeção, abre a \"caixa 5\" para ter certeza de que o dado é bom. Se você abrisse a caixa e visse um borrão ou uma imagem errada, saberia que o modelo nunca aprenderia direito. É o seu controle de qualidade.\n",
        "\n",
        "##Papel da IA (model.fit):\n",
        "Ela não precisa do plt.imshow. Ela \"engole\" as 60.000 matrizes de números de uma vez. Ela compara cada matriz com o rótulo correspondente e vai ajustando os milhares de pesos ($W$) e bias ($b$) até que a matemática faça sentido para todas as imagens.\n",
        "No modelo os 128 neurônios da camada oculta começam a se organizar:\n",
        "Um grupo de neurônios pode se especializar em detectar linhas verticais (mangas).\n",
        "Outro grupo pode se especializar em detectar o vazio entre as pernas (calças).\n",
        "A combinação desses sinais é o que faz a IA \"concluir\" o que é uma camisa."
      ],
      "metadata": {
        "id": "ZNA1cdh8xvAz"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPc9d3gJ3jWF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "37112eb2-582f-4c52-b86c-1c35fde589c3"
      },
      "source": [
        "# Imagem de treinamento e um rótulo de treinamento, experimentar com diferentes índices na matriz.\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(training_images[5])\n",
        "print(training_labels[5])#NUMERO REFERENCIA DO CALCADO ESPECIFICO\n",
        "print(training_images[5]) #MATRIZ DE PIXEL DE UM CALCADO ESPECIFICO\n",
        "\n",
        "# Img em numeros/Intensidade de pixel = 0 espaço vazio(preto) / 255 parte da roupa(branco/cinza claro)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "[[0.         0.         0.         0.         0.00392157 0.\n",
            "  0.         0.         0.         0.08627451 0.34509804 0.7372549\n",
            "  0.6745098  0.51764706 0.49019608 0.55294118 0.78039216 0.56078431\n",
            "  0.03529412 0.         0.         0.         0.00392157 0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.00392157 0.         0.\n",
            "  0.07843137 0.51372549 0.78039216 0.80784314 0.76862745 0.79215686\n",
            "  0.94901961 1.         1.         0.98039216 0.87058824 0.77254902\n",
            "  0.80784314 0.7372549  0.49411765 0.06666667 0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.00392157 0.         0.1372549\n",
            "  0.83921569 0.74901961 0.71764706 0.69803922 0.68627451 0.65882353\n",
            "  0.58823529 0.63529412 0.62352941 0.59607843 0.61960784 0.70196078\n",
            "  0.71764706 0.74117647 0.76470588 0.7254902  0.32156863 0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.66666667\n",
            "  0.74509804 0.6745098  0.69411765 0.69019608 0.67058824 0.6627451\n",
            "  0.63529412 0.60784314 0.58039216 0.60392157 0.6627451  0.68235294\n",
            "  0.68627451 0.68627451 0.69411765 0.71764706 0.7372549  0.04705882\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.09803922 0.76078431\n",
            "  0.70588235 0.69803922 0.68235294 0.72156863 0.73333333 0.74117647\n",
            "  0.73333333 0.72156863 0.70980392 0.74117647 0.78431373 0.77254902\n",
            "  0.75686275 0.74509804 0.69803922 0.68627451 0.76078431 0.35294118\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.16470588 0.85490196\n",
            "  0.74901961 0.77254902 0.81568627 0.8        0.82745098 0.81960784\n",
            "  0.82352941 0.83137255 0.82745098 0.83921569 0.84313725 0.83529412\n",
            "  0.83921569 0.82745098 0.82745098 0.74901961 0.78431373 0.61960784\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.34509804 0.86666667\n",
            "  0.84313725 0.85098039 0.85882353 0.82745098 0.7254902  0.58823529\n",
            "  0.4627451  0.41960784 0.38823529 0.34509804 0.3254902  0.35294118\n",
            "  0.52941176 0.83137255 0.79607843 0.81176471 0.85882353 0.6627451\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.10588235\n",
            "  0.4627451  0.63529412 0.15686275 0.         0.         0.\n",
            "  0.03921569 0.0745098  0.10980392 0.15294118 0.18431373 0.14117647\n",
            "  0.         0.         0.79607843 0.90196078 0.8627451  0.79607843\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.54117647 0.53333333\n",
            "  0.27843137 0.27058824 0.21176471 0.84705882 0.85098039 0.79607843\n",
            "  0.72156863 0.65882353 0.63921569 0.63529412 0.63921569 0.69803922\n",
            "  0.86666667 0.72941176 0.14901961 0.10196078 0.02745098 0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.2627451  0.5254902\n",
            "  0.60392157 0.87843137 0.50588235 0.25882353 0.31764706 0.45882353\n",
            "  0.50588235 0.50196078 0.51764706 0.5372549  0.51372549 0.50588235\n",
            "  0.3372549  0.28627451 0.61568627 0.59215686 0.5254902  0.84705882\n",
            "  0.07058824 0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.79607843 0.77647059\n",
            "  0.6745098  0.71764706 0.80784314 1.         1.         0.98039216\n",
            "  0.95294118 0.94117647 0.9372549  0.92156863 0.93333333 0.95686275\n",
            "  1.         0.93333333 0.72156863 0.62745098 0.3372549  0.38431373\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.47843137 0.7372549\n",
            "  0.87843137 0.59215686 0.41176471 0.49803922 0.38039216 0.39215686\n",
            "  0.41176471 0.44705882 0.45882353 0.45882353 0.44313725 0.40392157\n",
            "  0.38431373 0.43529412 0.55686275 0.99607843 0.74901961 1.\n",
            "  0.19215686 0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.63921569 0.70196078\n",
            "  0.78431373 0.37254902 0.60392157 0.77647059 0.77254902 0.78431373\n",
            "  0.78431373 0.77647059 0.77254902 0.77647059 0.78039216 0.79215686\n",
            "  0.78431373 0.69019608 0.3372549  0.80784314 0.61568627 0.63529412\n",
            "  0.03921569 0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.77254902 0.78823529\n",
            "  0.89803922 0.27843137 0.56470588 0.76078431 0.70980392 0.71764706\n",
            "  0.70196078 0.71372549 0.70588235 0.70196078 0.70588235 0.74509804\n",
            "  0.7254902  0.77254902 0.29803922 0.85882353 0.7254902  0.78823529\n",
            "  0.13333333 0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.78039216 0.75686275\n",
            "  0.88627451 0.22745098 0.60392157 0.75294118 0.72156863 0.73333333\n",
            "  0.72156863 0.72941176 0.72156863 0.7254902  0.71764706 0.75294118\n",
            "  0.74901961 0.78431373 0.21960784 0.85882353 0.79607843 0.81176471\n",
            "  0.23529412 0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.78823529 0.76078431\n",
            "  0.87843137 0.16078431 0.63921569 0.74509804 0.72941176 0.72941176\n",
            "  0.72156863 0.7254902  0.71764706 0.7254902  0.69803922 0.74509804\n",
            "  0.76078431 0.79215686 0.12941176 0.82745098 0.78431373 0.80784314\n",
            "  0.28627451 0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.78823529 0.77254902\n",
            "  0.87058824 0.06666667 0.6745098  0.74509804 0.72941176 0.73333333\n",
            "  0.71372549 0.72941176 0.7254902  0.73333333 0.70588235 0.73333333\n",
            "  0.75686275 0.79215686 0.10196078 0.83137255 0.79215686 0.79607843\n",
            "  0.29803922 0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.78431373 0.77254902\n",
            "  0.8745098  0.         0.69411765 0.74117647 0.72156863 0.7254902\n",
            "  0.69803922 0.72156863 0.71764706 0.72156863 0.70588235 0.71764706\n",
            "  0.74117647 0.79607843 0.1372549  0.76862745 0.79607843 0.79607843\n",
            "  0.32941176 0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.78431373 0.77254902\n",
            "  0.8745098  0.         0.7254902  0.73333333 0.7254902  0.73333333\n",
            "  0.70588235 0.72156863 0.71372549 0.71764706 0.69803922 0.71372549\n",
            "  0.71764706 0.80392157 0.17254902 0.62352941 0.81176471 0.78823529\n",
            "  0.33333333 0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.73333333 0.77647059\n",
            "  0.88235294 0.         0.76078431 0.7372549  0.72156863 0.7254902\n",
            "  0.70588235 0.71764706 0.71764706 0.72156863 0.70980392 0.70980392\n",
            "  0.69411765 0.80784314 0.18039216 0.50588235 0.82745098 0.78431373\n",
            "  0.34509804 0.         0.         0.        ]\n",
            " [0.         0.         0.         0.02352941 0.72941176 0.78431373\n",
            "  0.82745098 0.         0.78039216 0.74117647 0.72156863 0.72156863\n",
            "  0.7254902  0.71372549 0.71764706 0.72156863 0.7254902  0.71372549\n",
            "  0.68627451 0.80392157 0.19607843 0.38039216 0.84705882 0.77254902\n",
            "  0.36470588 0.         0.         0.        ]\n",
            " [0.         0.         0.         0.01960784 0.7254902  0.8\n",
            "  0.72156863 0.         0.79215686 0.7372549  0.71372549 0.71372549\n",
            "  0.71764706 0.71764706 0.72156863 0.71372549 0.70588235 0.71372549\n",
            "  0.68235294 0.79215686 0.24705882 0.23137255 0.8627451  0.76862745\n",
            "  0.36862745 0.         0.         0.        ]\n",
            " [0.         0.         0.         0.01960784 0.72156863 0.80784314\n",
            "  0.61568627 0.         0.8        0.73333333 0.73333333 0.74117647\n",
            "  0.75294118 0.74509804 0.74509804 0.74901961 0.74509804 0.73333333\n",
            "  0.71764706 0.79215686 0.30588235 0.1372549  0.87058824 0.77254902\n",
            "  0.37254902 0.         0.         0.        ]\n",
            " [0.         0.         0.         0.01960784 0.71764706 0.81568627\n",
            "  0.49803922 0.         0.77254902 0.65098039 0.6        0.58431373\n",
            "  0.58431373 0.57254902 0.58039216 0.58431373 0.58823529 0.59215686\n",
            "  0.61960784 0.74901961 0.35294118 0.03137255 0.8745098  0.76470588\n",
            "  0.38823529 0.         0.         0.        ]\n",
            " [0.         0.         0.         0.02352941 0.72156863 0.81568627\n",
            "  0.44705882 0.         0.8        0.67843137 0.63137255 0.70588235\n",
            "  0.69019608 0.6745098  0.67843137 0.67843137 0.68235294 0.69019608\n",
            "  0.63529412 0.79215686 0.45098039 0.         0.89803922 0.78039216\n",
            "  0.41176471 0.         0.         0.        ]\n",
            " [0.         0.         0.         0.03529412 0.69803922 0.8\n",
            "  0.45098039 0.         0.4745098  0.52941176 0.44705882 0.45882353\n",
            "  0.44705882 0.44705882 0.45882353 0.4627451  0.46666667 0.45882353\n",
            "  0.44313725 0.57647059 0.24705882 0.         0.88235294 0.76862745\n",
            "  0.41960784 0.         0.         0.        ]\n",
            " [0.         0.         0.         0.07058824 0.70588235 0.80784314\n",
            "  0.51372549 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.87843137 0.77254902\n",
            "  0.48235294 0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.55294118 0.59215686\n",
            "  0.29803922 0.         0.00392157 0.00392157 0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.52156863 0.65490196\n",
            "  0.28627451 0.         0.         0.        ]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cbrdH225_nH"
      },
      "source": [
        "Você vai notar que todos os valores no número estão entre 0 e 255. Se estivermos treinando uma rede neural, por vários motivos, é mais fácil tratar todos os valores como estando entre 0 e 1, um processo chamado de '**normalização**' e, felizmente, em Python é fácil normalizar uma lista como essa sem usar um loop."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRH19pWs6ZDn"
      },
      "source": [
        "# Normalizar uma lista sem usar um loop.\n",
        "# Acurácia de Treino/Acurácia de Teste\n",
        "training_images  = training_images / 255.0\n",
        "test_images = test_images / 255.0"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DkO0As46lRn"
      },
      "source": [
        "Existem dois conjuntos(treinamento e teste)  A ideia é ter um conjunto de dados para treinamento e outro conjunto de dados que o modelo ainda não viu, para ver o quão bem ele se sairia na classificação de valores. Afinal, quando terminar, você vai querer testá-lo com dados que ele nunca viu antes!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mAyndG3kVlK"
      },
      "source": [
        "#PROJETANDO O MODELO\n",
        "#Imagine que a foto da pata do cavalo é uma grade. O computador não entende \"grade\" nativamente é camadas densas.\n",
        "#Camada Flatten:não tem neurônios, apenas pega a imagem de 28x28 pixels e a \"estica\" em uma linha de 784 números.\n",
        "#O Flatten desmancha a grade e coloca todos os pixels em uma fila única.\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
        "                                    #Primeira camada Dense (Oculta): tem 128 neurônios. Cada um desses 128 neurônios,está conectado a todos os 784 pixels da entrada.\n",
        "                                    #Filtro de importância — ela descarta sinais negativos que não ajudam na detecção de padroes.\n",
        "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "                                    #Segunda camada Dense (Saída):tem 10 neurônios (um para cada categoria de roupa: bota, camiseta, etc).\n",
        "                                    #Softmax entrega a resposta em probabilidade (ex: 90% de chance de ser a bota).\n",
        "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lUcWaiX7MFj"
      },
      "source": [
        "**Sequencial**: Define uma SEQUÊNCIA de camadas na rede neural.\n",
        "\n",
        "**Aplanar**: Lembra-se de quando nossas imagens eram um quadrado ao serem impressas? Aplanar simplesmente transforma esse quadrado em um conjunto unidimensional.\n",
        "\n",
        "**Denso**: Adiciona uma camada de neurônios. É o modelo do neurônio. Quando você chama Dense, você está dizendo: \"Quero aquele neurônio clássico que o professor me ensinou nos fundamentos (que faz soma ponderada e ativação)\".\n",
        "\n",
        "O parâmetro 128: É a quantidade. Você está encomendando 128 unidades desse modelo de neurônio.\n",
        "\n",
        "A activation: É a configuração interna. Você está dizendo que cada um desses 128 neurônios deve vir de fábrica com uma \"válvula\" ReLU instalada na saída.\n",
        "Cada camada de neurônios precisa de uma **função de ativação** para instruí-los sobre o que fazer.\n",
        "\n",
        "**ReLU** significa, efetivamente, \"Se X > 0, retorne X; caso contrário, retorne 0\" — ou seja, ela passa apenas valores iguais ou maiores que 0 para a próxima camada da rede.\n",
        "\n",
        "** **Softmax** pega um conjunto de valores e escolhe o maior deles. Por exemplo, se a saída da última camada for [0.1, 0.1, 0.05, 0.1, 9.5, 0.1, 0.05, 0.05, 0.05], ela evita que você precise procurar o maior valor, transformando-o em [0,0,0,0,1,0,0,0,0] — o objetivo é economizar bastante código!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8vbMCqb9Mh6"
      },
      "source": [
        "O próximo passo, agora que o modelo está definido, é construí-lo. Isso é feito compilando-o com um otimizador e uma função de perda, como antes, e então treinando-o ao chamar o método `model.fit`, solicitando que ele ajuste os dados de treinamento aos rótulos de treinamento — ou seja, que determine a relação entre os dados de treinamento e seus rótulos reais. Assim, no futuro, se você tiver dados semelhantes aos dados de treinamento, o modelo poderá prever como esses dados se comportarão."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLMdl9aP8nQ0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c483ad9-3a4c-4d51-cf44-139d0bf63d7d"
      },
      "source": [
        "# Compila com um otimizador e funcao de perda loss\n",
        "# 1 epoca - todas as imagens analisadas\n",
        "# Loss(perda) - diminui conforma epocas\n",
        "# Acuracia(precisão) - aumenta conforma epocas\n",
        "# Adam - versão \"turbinada\" do Gradiente Descendente.\n",
        "# Enquanto o GD comum desce a montanha em passos constantes, o Adam ajusta a velocidade da descida para cada peso individualmente (ele tem \"memória\").\n",
        "# Quando ele age? Toda vez que o model.fit processa um lote de imagens, o Adam calcula o erro (Loss), vê para que lado a montanha desce (Gradiente) e empurra os pesos naquela direção.\n",
        "model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "\n",
        "# ACURACIA E LOSS são a média de erro e acerto sobre as 60.000 imagens simultaneamente."
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.5574 - loss: 1.4770\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.7607 - loss: 0.6618\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.7968 - loss: 0.5693\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8140 - loss: 0.5288\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.8247 - loss: 0.4923\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x799390139610>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JJMsvSB-1UY"
      },
      "source": [
        "Após o treinamento, você deverá ver um valor de ACÚRACIA ao final da última época. Pode ser algo como 0,9098. Isso indica que sua rede neural tem uma acurácia de aproximadamente 91% na classificação dos dados de treinamento. Ou seja, ela identificou uma correspondência de padrão entre a imagem e os rótulos em 91% dos casos. Não é ótimo, mas também não é ruim considerando que o treinamento durou apenas 5 épocas e foi concluído rapidamente.\n",
        "\n",
        "Mas como ela se comportaria com dados não vistos? É por isso que temos as imagens de teste. Podemos chamar o método `model.evaluate`, passando os dois conjuntos de dados, e ele retornará a perda para cada um. Vamos experimentar:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzlqsEzX9s5P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85d6e108-f757-4fd4-e6fb-ae01c71cac9b"
      },
      "source": [
        "# GENERALIZAÇÃO - capacidade do modelo de manter um desempenho alto em dados que ele nunca viu.\n",
        "# Acurácia de Treino: O quanto ele aprendeu com os exemplos que viu.\n",
        "# Acurácia de Teste (Evaluate): O quanto ele aprendeu o conceito geral.\n",
        "# ve a perda entre acuracia de treino e de teste\n",
        "# O QUE SERA PRECISO: modelo aprenda o movimento da pata e não apenas decore o fundo da fazenda ou a cor de um cavalo específico. Generalização.\n",
        "model.evaluate(test_images, test_labels)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8718 - loss: 0.3559\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3522093892097473, 0.8736000061035156]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tki-Aro_Uax"
      },
      "source": [
        "Para mim, isso resultou em uma precisão de aproximadamente 0,8838, o que significa uma acurácia de cerca de 88%. Como esperado, provavelmente não teria o mesmo desempenho com dados *não vistos* que teve com os dados usados ​​no treinamento! Ao longo deste curso, você verá maneiras de melhorar isso.\n"
      ]
    }
  ]
}